{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring\n",
    "Produce a geoJSON file containing the trueskill score associated to the perceived safety of a certain location (by analyzing pictures of that location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import trueskill\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import logging\n",
    "import random\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "logger = tensorflow.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "Adjust these to reflect the desired input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_path = \"models/atmos_finetuning_full.h5\"\n",
    "training_path = \"enhanced_preproc/\"\n",
    "data_path = \"data/\"\n",
    "csv_name = \"scoring.csv\"\n",
    "img_folder = \"data/images/\"\n",
    "output_file = \"output/atmos_hardturm_27k_exp30.geojson\"\n",
    "training_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Select which GPU to use when several are available. This can be removed when few GPUs are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained ML model to compare image couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 09:37:17.928530: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-09 09:37:17.929642: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-09 09:37:17.932808: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "siamese_net = load_model(network_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select images from training set to be used as a baseline to compute trueskill score of other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images\n",
    "training_images = {}\n",
    "\n",
    "# Select, load and preprocess 30 random items from the training set \n",
    "for f in random.sample(os.listdir(training_path), training_size):\n",
    "    training_images[f[:-4]] = preprocess_input(cv2.imread(training_path+f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute trueskill score of all images used as training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores = {id : trueskill.Rating() for id in training_images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 09:37:20.172600: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-09 09:37:20.191235: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n"
     ]
    }
   ],
   "source": [
    "trainingCouples = itertools.combinations(training_images.keys(), 2)\n",
    "\n",
    "leftIds = []\n",
    "rightIds = []\n",
    "\n",
    "for c in trainingCouples:\n",
    "    leftIds.append(c[0])\n",
    "    rightIds.append(c[1])\n",
    "\n",
    "left = np.array([training_images[l] for l in leftIds])\n",
    "right = np.array([training_images[r] for r in rightIds])\n",
    "\n",
    "result = siamese_net.predict([left, right])\n",
    "\n",
    "for j,r in enumerate(result):\n",
    "    if r[1]>r[0]: #left wins\n",
    "        newL, newR = trueskill.rate_1vs1(training_scores[leftIds[j]], training_scores[rightIds[j]])\n",
    "        training_scores[leftIds[j]] = newL\n",
    "        training_scores[rightIds[j]] = newR\n",
    "    else:\n",
    "        newR, newL = trueskill.rate_1vs1(training_scores[rightIds[j]], training_scores[leftIds[j]])\n",
    "        training_scores[leftIds[j]] = newL\n",
    "        training_scores[rightIds[j]] = newR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Create dictionary containing images to be scored from csv file, and associated metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['341465924096747', 'ZZH', '47.41368135522427', '8.481477499008179', '69.001520727037', 'LngVh2kfbHV6xww5dRjJbw', '1540311254600', 'False']\n"
     ]
    }
   ],
   "source": [
    "metadata = {}\n",
    "with open(data_path+csv_name) as f:\n",
    "    csv_data = csv.reader(f)\n",
    "    print(next(csv_data))\n",
    "    for r in csv_data:\n",
    "        metadata[r[0]] = {\"coord\": [r[2], r[3]], \"score\": trueskill.Rating()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess images to be scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@445.495] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('data/images/1026293164858134.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "images = {}\n",
    "for imName in metadata.keys():\n",
    "    im = cv2.imread(img_folder+imName+\".jpg\")\n",
    "\n",
    "    if im is not None:\n",
    "        im = cv2.resize(im, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        images[imName] = preprocess_input(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores computation\n",
    "Compute scores for images to be analyzed by comparing them with images from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIds = np.array(list(training_images.keys()))\n",
    "i = 0\n",
    "m = len(images.keys())\n",
    "                    \n",
    "for imgId, img in images.items():\n",
    "    i+=1\n",
    "    print(i/m*100, end = '\\r')\n",
    "    left = np.array([training_images[tId] for tId in trainIds])\n",
    "    right = np.array([img for tId in trainIds])\n",
    "\n",
    "    result = siamese_net.predict([left, right])\n",
    "\n",
    "    for j,r in enumerate(result):\n",
    "        if r[1]>r[0]: #left wins\n",
    "            _ ,metadata[imgId][\"score\"] = trueskill.rate_1vs1(training_scores[leftIds[j]], metadata[imgId][\"score\"])\n",
    "        else: #right wins\n",
    "            metadata[imgId][\"score\"], _ = trueskill.rate_1vs1(metadata[imgId][\"score\"], training_scores[leftIds[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the \"mu\" value of the trueskill scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental: compare also the analyzed images\n",
    "i = 0\n",
    "m = len(images.keys())\n",
    "                    \n",
    "for imgId, img in images.items():\n",
    "    i+=1\n",
    "    print(i/m*100, end = '\\r')\n",
    "    leftIds = [tId for tId in random.sample(images.keys(),30)]\n",
    "    left = np.array([images[tId] for tId in leftIds])\n",
    "    right = np.array([img for tId in range(0,30)])\n",
    "\n",
    "    result = siamese_net.predict([left, right])\n",
    "\n",
    "    for j,r in enumerate(result):\n",
    "        if r[1]>r[0]: #left wins\n",
    "            metadata[leftIds[j]][\"score\"] ,metadata[imgId][\"score\"] = trueskill.rate_1vs1(metadata[leftIds[j]][\"score\"], metadata[imgId][\"score\"])\n",
    "        else: #right wins\n",
    "            metadata[imgId][\"score\"], metadata[leftIds[j]][\"score\"] = trueskill.rate_1vs1(metadata[imgId][\"score\"], metadata[leftIds[j]][\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "mink = list(metadata.keys())[0]\n",
    "maxk = list(metadata.keys())[0]\n",
    "\n",
    "for k in metadata.keys():\n",
    "    if type(metadata[k][\"score\"]) is dict:\n",
    "        metadata[k][\"score\"] = metadata[k][\"score\"].mu\n",
    "    \n",
    "    if metadata[k][\"score\"] > metadata[maxk][\"score\"]:\n",
    "        maxk = k\n",
    "    if metadata[k][\"score\"] < metadata[mink][\"score\"]:\n",
    "        mink = k  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(im1, im2, label):\n",
    "    im1 = im1+127.5\n",
    "    im1[im1>255] = 255\n",
    "    im1 = cv2.cvtColor(im1.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    im2 = im2+127.5\n",
    "    im2[im2>255] = 255\n",
    "    im2 = cv2.cvtColor(im2.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize = (15,10))\n",
    "    ax1.imshow(im1)\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(im2)\n",
    "    ax2.axis('off')\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "\n",
    "display_images(images[mink], images[maxk], \"min, max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data to geoJSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson = {\"type\": \"FeatureCollection\",\n",
    "  \"features\":[]}\n",
    "\n",
    "for k, v in metadata.items():\n",
    "    geojson[\"features\"].append({\"type\": \"Feature\",\n",
    "                   \"properties\": {\n",
    "                       \"name\": k,\n",
    "                       \"score\": v[\"score\"]\n",
    "                   },\n",
    "                   \"geometry\": {\n",
    "                       \"type\": \"Point\",\n",
    "                       \"coordinates\": [float(v[\"coord\"][1]), float(v[\"coord\"][0])]\n",
    "                   }})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save geoJSON data to external json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w') as fp:\n",
    "    json.dump(geojson, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
